# -*- coding: utf-8 -*-
"""solarpanels_notebook-data-extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s0Dnb2rflvbkePP91uRKFO0khTl75MS4

#  **NASA SUNSHINE DATA MINING**
"""

import pandas as pd
import requests
import json as js

from Tools.scripts.dutree import display
from bs4 import BeautifulSoup
from pyspark.sql.functions import pandas_udf
from pyspark.sql import SparkSession
import time
from pyspark.sql.types import StringType, DoubleType

import geopy
from geopy.geocoders import Nominatim

Parameters = {
    "QV2M": "MERRA-2 Specific Humidity at 2 Meters (g/kg)",
    "RH2M": "MERRA-2 Relative Humidity at 2 Meters (%)",
    "ALLSKY_KT": "CERES SYN1deg All Sky Insolation Clearness Index (dimensionless)",
    "CLOUD_AMT": "CERES SYN1deg Cloud Amount (%)",
    "CLRSKY_KT": "CERES SYN1deg Clear Sky Insolation Clearness Index (dimensionless)",
    "TOA_SW_DWN": "CERES SYN1deg Top-Of-Atmosphere Shortwave Downward Irradiance (kW-hr/m^2/day)",
    "PRECTOTCORR": "MERRA-2 Precipitation Corrected (mm/day)",
    "ALLSKY_SFC_UVA": "CERES SYN1deg All Sky Surface UVA Irradiance (W/m^2)",
    "ALLSKY_SFC_UVB": "CERES SYN1deg All Sky Surface UVB Irradiance (W/m^2)",
    "ALLSKY_SRF_ALB": "CERES SYN1deg All Sky Surface Albedo (dimensionless)",
    "PRECTOTCORR_SUM": "MERRA-2 Precipitation Corrected Sum (mm)",
    "ALLSKY_SFC_SW_DNI": "CERES SYN1deg All Sky Surface Shortwave Downward Direct Normal Irradiance (kW-hr/m^2/day)",
    "ALLSKY_SFC_SW_DWN": "CERES SYN1deg All Sky Surface Shortwave Downward Irradiance (kW-hr/m^2/day)",
    "CLRSKY_SFC_SW_DWN": "CERES SYN1deg Clear Sky Surface Shortwave Downward Irradiance (kW-hr/m^2/day)",
    "ALLSKY_SFC_PAR_TOT": "CERES SYN1deg All Sky Surface PAR Total (W/m^2)",
    "ALLSKY_SFC_SW_DIFF": "CERES SYN1deg All Sky Surface Shortwave Diffuse Irradiance (kW-hr/m^2/day)",
    "CLRSKY_SFC_PAR_TOT": "CERES SYN1deg Clear Sky Surface PAR Total (W/m^2)",
    "ALLSKY_SFC_UV_INDEX": "CERES SYN1deg All Sky Surface UV Index (dimensionless)"
}

parameters = list(Parameters.keys())

""" For more information's, parameter dictionary has been add on [NASA site](https://power.larc.nasa.gov/) at the bottom 
of the page. You may have more definiton of the parameter you'll find it out.
"""

# Récupération des villes Selon les données de récensement 2021.
# Extraction des données par Webscraping (source de données wikipédia)


URL = "https://fr.wikipedia.org/wiki/Liste_des_communes_de_C%C3%B4te_d%27Ivoire_les_plus_peupl%C3%A9es"
response = requests.get(URL)

# récupération des premières données
columns_names = ["ville", "2021", "2014", "1998", "1988", "1975", "region"]
data_stock = pd.DataFrame(columns=columns_names)

# Vérifier si la requête a réussi
if response.status_code == 200:
    # Utiliser BeautifulSoup pour analyser le contenu HTML
    soup = BeautifulSoup(response.content, 'html.parser')

    # Trouver la table contenant les informations sur les communes
    table = soup.find('table')

    # Parcourir les lignes de la table pour récupérer les données
    if table:
        rows = table.find_all('tr')[1:]
        for row in rows:
            # Récupérer les cellules de chaque ligne
            cells = row.find_all('td')[1:]  # possibilité de recherhcer plusieurs balises ex :['th', 'td']

            ville = cells[0].text.strip()
            a_2021 = cells[1].text.strip()
            a_2014 = cells[2].text.strip()
            a_1998 = cells[3].text.strip()
            a_1988 = cells[4].text.strip()
            a_1975 = cells[5].text.strip()
            region = cells[6].text.strip()

            new_row = pd.Series(
                {
                    "ville": ville,
                    # gestion des nombres strings: "number"
                    "2021": a_2021.replace(' ', ''),
                    "2014": a_2014.replace(' ', ''),
                    "1998": a_1998.replace(' ', ''),
                    "1988": a_1988.replace(' ', ''),
                    "1975": a_1975.replace(' ', ''),
                    "region": region
                }
            )

            data_stock = pd.concat(
                [
                    data_stock, new_row.to_frame().T
                    # have a dataframe type as that of data_stock
                    # with series types
                ],
                ignore_index=True
            )

            # Afficher le texte des cellules

else:
    print("Nous n'avons pas pu récupérer les données")

valuehandled = []
for value in list(data_stock['2021']):
    valuehandled.append(value.replace(' ', ''))

data = data_stock.copy(deep=True)
data = data.convert_dtypes()
data.replace("NA", "NaN")

dtype_params = {

    "ville": str,
    "2021": int,
    "2014": int,
    "1998": int,
    "1988": int,
    "1975": int,
    "region": str
}

"""Traitement de la coquille dans dans la colonne "2021"."""


# fonction de remplacement des valeurs de NA par NaN
def na_to_nan(x):
    return x.replace("NA", "NaN", inplace=True)


data_stock.replace("NA", "NaN", inplace=True)

col_name = list(data_stock.columns)
for col in col_name:
    if col in ['ville', "region"]:
        data_stock[col] = data_stock[col].convert_dtypes()

    else:

        # transformation des colonnes considérées en valeur numérique
        data_stock[col] = pd.to_numeric(
            data_stock[col],
            errors='coerce',
            downcast='float'
        )
        print(col, data_stock[col].dtypes)

# Récupération des données de position des villes via l'API GeoPy

geolocat = Nominatim(user_agent="solarpanels_app")


# building execution time of every functions


def function_exec_time(funct):
    def wrapper(*args, **kwargs):
        start = time.time()
        result = funct(*args, **kwargs)
        end = time.time()
        execution_time = end - start
        print(f"execution time of this function is : {(end - start):.4f} s")
        return result

    return wrapper


# fonction de localisation
@function_exec_time
def location(x: str, key):
    """
      location_type can be lon or lat
      if you want longitude, function input is lon
      if you want latitude, function input is lat
      Adding the key is strongly couraged
    """

    # intanciation de la classe Nominatim
    geoloc = Nominatim(user_agent="solarpanels_app")

    key = key

    if key == "lon":
        return geoloc.geocode(x).longitude

    elif key == "lat":
        return geoloc.geocode(x).latitude

    else:
        print("enter a right key, 'either' lon or 'lat', not another key")


location("abidjan", "lon")


def double(x):
    return x * 2


data = data_stock.copy(deep=True)
df = data_stock.copy(deep=True)

data_stock["longitude"] = data['ville'].apply(lambda x: location(x, "lon"))
data_stock["latitude"] = data['ville'].apply(lambda x: location(x, "lat"))


# Création d'une fonction UDF

ps = SparkSession \
    .builder \
    .appName("python spark sql") \
    .config("spark.some.config.option", "some-value") \
    .getOrCreate()

ps_df = ps.createDataFrame(data_stock)

"""#### **Traitement avec la fonction pandas_udf.**"""


# fonction de localisation
@function_exec_time
def location(villes: str, coord_type):
    """
  location_type can be lon or lat
  if you want longitude, function input is lon in lieu of coor_type
  if you want latitude, function input is lat in lieu of coor_type
  Adding the key is strongly couraged
  """
    # intanciation de la classe Nominatim
    geoloc = Nominatim(user_agent="solarpanels_app")

    key = coord_type

    if key == "lon":
        return geoloc.geocode(villes).longitude

    elif key == "lat":
        return geoloc.geocode(villes).latitude

    else:
        print("enter a right coord_type, 'either' lon or 'lat', not another key")


# Création de la pandas_udf pour obtenir la longitude

@function_exec_time
@pandas_udf(DoubleType())
def get_location_lon(villes):
    return villes.apply(lambda x: location(x, "lon"))


# Création de la pandas_udf pour obtenir la latitude
# Renvoyant des décimaux
@function_exec_time
@pandas_udf(DoubleType())
def get_location_lat(villes):
    return villes.apply(lambda x: location(x, "lat"))


psdata = ps.createDataFrame(data)
psdata = psdata.withColumn("longitude",
                           get_location_lon(psdata['ville']))  # is it possible with get_location_lon("ville")
psdata = psdata.withColumn("latitude",
                           get_location_lat(psdata['ville']))  # is it possible with get_location_lat("ville")


display(psdata)

"""Data saving"""

psdata.toPandas().to_csv("cities-data-and-location.csv", index=False)

